#create a list of MP3 names 
import pandas as pd 
data = pd.read_csv("info.csv") # <----- data file that will dictates the order of mp3s (their phonemes and features) in reps. 

origs = ['pizza','person','table','tennis','dog', 'cake', 'game', 'girl', 'kite', 'bench', 'boat', 'day']
manips =['beetza','berson', 'dable', 'dennis', 'tog', 'gayk', 'kame', 'kirl', 'guyte', 'pench', 'poat', 'tay']

manipulated_mp3 =[]
MP3=[]
for element in data['path']:
    MP3.append(element)
    
original_mp3 = MP3.copy()
    

for element in MP3:
    x =element.split('_')[0].split('.')[0]
    if x in manips:
        original_mp3.remove(element)
        manipulated_mp3.append(element)
       
       
#import the audio alignment file generated by the Gentle toolkit and create a dictionary with embedded dictionary for each MP3 

import json
with open('fa.json') as X:
    fa= json.load(X)
FA = dict((utt['path'], utt) for utt in fa)


#count the phonemes for each MP3 name and compile them in dicionaries and manually adjust the one of malformed mp3 (GTTS malfunction)

PHO_manips={}
for mp3 in manipulated_mp3:
    total = 0
    for word in FA[mp3]['words']:
        phoneme_count = len(word['phones'])
        total=total+phoneme_count
    PHO_manips[mp3]=total
    
PHO_manips['gayk__155179.mp3']=26
PHO_manips['kame.mp3']=18
PHO_manips['kame__12639.mp3']=19
PHO_manips['kirl_1.mp3']=19
PHO_manips['kirl__546475.mp3']= 23

PHO_org={}
for mp3 in original_mp3:
    total = 0
    for word in FA[mp3]['words']:
        phoneme_count = len(word['phones'])
        total=total+phoneme_count
    PHO_org[mp3]=total
    PHO_org['cake__155179.mp3']=26
    PHO_org['game.mp3']=18
    PHO_org['game__12639.mp3']=19
    PHO_org['girl_1.mp3']=19
    PHO_org['girl__546475.mp3']= 23


#import the phoneme and features representations to separte each MP3 from another and complie them in dictionaries 
import numpy as np 
T = np.load("test_rec2_phonemes.npy")
L = np.load("test_rec2_features.npy")

orig_manips = dict(**PHO_org, **PHO_manips)
both_mp3_pho={}
both_mp3_features ={}

start = 0
end = orig_manips[data.iloc[0]['path']]

for index, row in data.iterrows():
    if index+1 < len(data['path']):
        both_mp3_pho[row['path']]=T[start:end]
        both_mp3_features[row['path']] = L[start:end]
        start = end 
        end = start + orig_manips[data.iloc[index+1]['path']]

        
both_mp3_pho['tog__82807.mp3'] = T[2579:] #out of index, last MP3 
both_mp3_features['tog__82807.mp3'] = L[2579:] #out of index, last MP3 


#create a dictionary of MP3 name and the phonemes prefix of the specific word as its value 

both_mp3_prefix={}

for element in both_mp3_pho:
    x =element.split('_')[0].split('.')[0]
    if x =='beetza' or x=='pizza':
        both_mp3_prefix[element]='piy'
    if x =='bench' or x=='pench':
        both_mp3_prefix[element]='beh'
    if x =='berson' or x=='person':
        both_mp3_prefix[element]='per'
    if x =='boat' or x=='poat':
        both_mp3_prefix[element]='bow'
    if x =='cake' or x=='gayk':
        both_mp3_prefix[element]='key'
    if x =='dable' or x=='table':
        both_mp3_prefix[element]='tey'
    if x =='day' or x=='tay':
        both_mp3_prefix[element]='dey'
    if x =='dennis' or x=='tennis':
        both_mp3_prefix[element]='teh'
    if x =='dog' or x=='tog':
        both_mp3_prefix[element]='dao'
    if x =='game' or x=='kame':
        both_mp3_prefix[element]='gey'
    if x =='girl' or x=='kirl':
        both_mp3_prefix[element]='ger'
    if x =='guyte' or x=='kite':
        both_mp3_prefix[element]='kay'


#define an indexing fonction to find the index of the phoneme of interest 
def find_index(a,b):
    for index,pho in np.ndenumerate(both_mp3_pho[a]):
        if index[0]+1<len(both_mp3_pho[a]):
            X = np.core.defchararray.add(pho,both_mp3_pho[a][index[0]+1])
            if X== b:
                return index[0]
                
#parse through MP3s phoneme dictionary to find the index of the specific phoneme in each array of phonemes
#create a dcitionary for each mp3 and the index of the phoneme of interest 

mp3_pho_idx={}

for mp3 in both_mp3_prefix:
    mp3_pho_idx[mp3]=find_index(mp3,both_mp3_prefix[mp3])


#create a list of tuples of matching mp3s (each mp3 and its counterpart with the manipulated end word)
matching_mp3 = [('beetza_1.mp3', 'pizza_1.mp3'),('beetza_161925.mp3','pizza__161925.mp3'), ('beetza_2.mp3','pizza_2.mp3'),
               ('beetza_385029.mp3', 'pizza__385029.mp3'),('bench__227478.mp3','pench__227478.mp3'),
               ('bench__349184.mp3','pench__349184.mp3'),('bench__464251.mp3','pench__464251.mp3'),
               ('bench__89697.mp3','pench__89697.mp3'), ('berson__35197.mp3', 'person__35197.mp3'),
               ('berson__460841.mp3','person__460841.mp3'),('berson__534601.mp3','person__534601.mp3'),
               ('berson__8021.mp3','person__8021.mp3'), ('boat.mp3','poat.mp3'), ('boat__116439.mp3','poat__116439.mp3'),
                ('boat__160728.mp3', 'poat__160728.mp3'),('boat__570448.mp3','poat__570448.mp3'),('cake.mp3','gayk.mp3') 
                ,('cake__155179.mp3', 'gayk__155179.mp3'), ('cake__334483.mp3', 'gayk__334483.mp3'),
                ('cake__405249.mp3','gayk__405249.mp3' ), ('dable__142620.mp3', 'table__142620.mp3' ), 
                ('dable__329455.mp3','table__329455.mp3'),('dable__405691.mp3','table__405691.mp3'),
                ('dable__87742.mp3', 'table__87742.mp3' ), ('day_1.mp3', 'tay_1.mp3'),('day_2.mp3','tay_2.mp3'), 
                ('day__179392.mp3','tay__179392.mp3'), ('day__312237.mp3','tay__312237.mp3'), 
               ('dennis__117744.mp3','tennis__117744.mp3'), ('dennis__379332.mp3','tennis__379332.mp3'),
                ('dennis__404922.mp3','tennis__404922.mp3'),('dennis__515828.mp3','tennis__515828.mp3'),
               ('dog_1.mp3','tog_1.mp3'), ('dog_2.mp3','tog_2.mp3'),('dog__140203.mp3','tog__140203.mp3'),
                ('dog__82807.mp3','tog__82807.mp3'), ('game.mp3','kame.mp3'),('game__12639.mp3','kame__12639.mp3'),
                ('game__237071.mp3','kame__237071.mp3') ,('game__302107.mp3','kame__302107.mp3'),
                ('girl_1.mp3','kirl_1.mp3'), ('girl_2.mp3','kirl_2.mp3'),('girl__445999.mp3','kirl__445999.mp3'),
                ('girl__546475.mp3','kirl__546475.mp3'),('guyte__124442.mp3','kite__124442.mp3'), 
                ('guyte__289960.mp3','kite__289960.mp3'), ('guyte__478721.mp3','kite__478721.mp3'), 
                ('guyte__511647.mp3','kite__511647.mp3'), ('guyte__7511.mp3','kite__7511.mp3')]
         
         
# create a Dictionary of specific positioned phonemes (original & manipulated) and their feature vectors.
def dict_specific_phoneme_per_layer(layer):
    layer={}
    for idx in range(len(matching_mp3)):
        key = np.delete(both_mp3_pho[matching_mp3[idx][0]],
                        [i for i in range(len(both_mp3_pho[matching_mp3[idx][0]])) if i!=mp3_pho_idx[matching_mp3[idx][0]]])[0]
        if matching_mp3[idx][0] in manipulated_mp3:
            layer[key+str(idx)]= {'manipulated':{'phoneme':np.delete(both_mp3_pho[matching_mp3[idx][0]],
                                                                    [i for i in range(len(both_mp3_pho[matching_mp3[idx][0]])) if i!=mp3_pho_idx[matching_mp3[idx][0]]]),
                                                'feature':np.array([both_mp3_features[matching_mp3[idx][0]][mp3_pho_idx[matching_mp3[idx][0]]]])},
                                 'original':{'phoneme':np.delete(both_mp3_pho[matching_mp3[idx][1]],
                                                                 [i for i in range(len(both_mp3_pho[matching_mp3[idx][1]])) if i!=mp3_pho_idx[matching_mp3[idx][1]]]),
                                             'feature':np.array([both_mp3_features[matching_mp3[idx][1]][mp3_pho_idx[matching_mp3[idx][1]]]])}}
        else:
            layer[key+str(idx)]= {'original':{'phoneme':np.delete(both_mp3_pho[matching_mp3[idx][0]],
                                                                 [i for i in range(len(both_mp3_pho[matching_mp3[idx][0]])) if i!=mp3_pho_idx[matching_mp3[idx][0]]]),
                                             'feature':np.array([both_mp3_features[matching_mp3[idx][0]][mp3_pho_idx[matching_mp3[idx][0]]]])},
                                 'manipulated':{'phoneme':np.delete(both_mp3_pho[matching_mp3[idx][1]],
                                                                    [i for i in range(len(both_mp3_pho[matching_mp3[idx][1]])) if i!=mp3_pho_idx[matching_mp3[idx][1]]]),
                                                'feature':np.array([both_mp3_features[matching_mp3[idx][1]][mp3_pho_idx[matching_mp3[idx][1]]]])}}
     
    return layer
    
    
    #final step 
    #separate all the manipualted phonemes and their feature vectors, from the original ones. 

def list_separated(layer):
    original_ph = np.array([], dtype='<U2')
    manipulated_ph = np.array([], dtype='<U2')
    for pho in dict_specific_phoneme_per_layer(layer):
        original_ph = np.append(original_ph,dict_specific_phoneme_per_layer(layer)[pho]['original']['phoneme'])
        manipulated_ph = np.append(manipulated_ph,dict_specific_phoneme_per_layer(layer)[pho]['manipulated']['phoneme'])
    
    original_feat = np.vstack(tuple([dict_specific_phoneme_per_layer(layer)[pho]['original']['feature'] for pho in dict_specific_phoneme_per_layer(layer)]))
    manipulated_feat = np.vstack(tuple([dict_specific_phoneme_per_layer(layer)[pho]['manipulated']['feature'] for pho in dict_specific_phoneme_per_layer(layer)]))
    
    dictionary = {'original':(original_ph,original_feat), 'manipulated':(manipulated_ph,manipulated_feat)}
    return dictionary
    
############################################################################################################################

# separate the different phonemes and their feature vectors (manipulated and original) from each other 

def letters_separate(layer):
    
    #original letters and their features 
    ori_feature_P = np.vstack(tuple([list_separated(layer)['original'][1][idx] 
                                 for idx, pho in enumerate(list_separated(layer)['original'][0]) if pho =='p']))
    ori_pho_P =np.array([], dtype='<U2')
    ori_pho_P = np.append(ori_pho_P, [pho for pho in list_separated(layer)['original'][0] if pho =='p'])
    
    ori_feature_B = np.vstack(tuple([list_separated(layer)['original'][1][idx] 
                                 for idx, pho in enumerate(list_separated(layer)['original'][0]) if pho =='b']))
    ori_pho_B =np.array([], dtype='<U2')
    ori_pho_B = np.append(ori_pho_B, [pho for pho in list_separated(layer)['original'][0] if pho =='b'])
    
    ori_feature_T = np.vstack(tuple([list_separated(layer)['original'][1][idx] 
                                 for idx, pho in enumerate(list_separated(layer)['original'][0]) if pho =='t']))
    ori_pho_T =np.array([], dtype='<U2')
    ori_pho_T = np.append(ori_pho_T, [pho for pho in list_separated(layer)['original'][0] if pho =='t'])
    
    ori_feature_K = np.vstack(tuple([list_separated(layer)['original'][1][idx] 
                                 for idx, pho in enumerate(list_separated(layer)['original'][0]) if pho =='k']))
    ori_pho_K =np.array([], dtype='<U2')
    ori_pho_K = np.append(ori_pho_K, [pho for pho in list_separated(layer)['original'][0] if pho =='k'])
    
    ori_feature_G = np.vstack(tuple([list_separated(layer)['original'][1][idx] 
                                 for idx, pho in enumerate(list_separated(layer)['original'][0]) if pho =='g']))
    ori_pho_G =np.array([], dtype='<U2')
    ori_pho_G = np.append(ori_pho_G, [pho for pho in list_separated(layer)['original'][0] if pho =='g'])
    
    ori_feature_D = np.vstack(tuple([list_separated(layer)['original'][1][idx] 
                                 for idx, pho in enumerate(list_separated(layer)['original'][0]) if pho =='d']))
    ori_pho_D =np.array([], dtype='<U2')
    ori_pho_D = np.append(ori_pho_D, [pho for pho in list_separated(layer)['original'][0] if pho =='d'])
    
    #manipulated letters and their features
    mani_feature_P = np.vstack(tuple([list_separated(layer)['manipulated'][1][idx] 
                                 for idx, pho in enumerate(list_separated(layer)['manipulated'][0]) if pho =='p']))
    mani_pho_P =np.array([], dtype='<U2')
    mani_pho_P = np.append(mani_pho_P, [pho for pho in list_separated(layer)['manipulated'][0] if pho =='p'])
    
    mani_feature_B = np.vstack(tuple([list_separated(layer)['manipulated'][1][idx] 
                                 for idx, pho in enumerate(list_separated(layer)['manipulated'][0]) if pho =='b']))
    mani_pho_B =np.array([], dtype='<U2')
    mani_pho_B = np.append(mani_pho_B, [pho for pho in list_separated(layer)['manipulated'][0] if pho =='b'])
    
    mani_feature_T = np.vstack(tuple([list_separated(layer)['manipulated'][1][idx] 
                                 for idx, pho in enumerate(list_separated(layer)['manipulated'][0]) if pho =='t']))
    mani_pho_T =np.array([], dtype='<U2')
    mani_pho_T = np.append(mani_pho_T, [pho for pho in list_separated(layer)['manipulated'][0] if pho =='t'])
    
    mani_feature_K = np.vstack(tuple([list_separated(layer)['manipulated'][1][idx] 
                                 for idx, pho in enumerate(list_separated(layer)['manipulated'][0]) if pho =='k']))
    mani_pho_K =np.array([], dtype='<U2')
    mani_pho_K = np.append(mani_pho_K, [pho for pho in list_separated(layer)['manipulated'][0] if pho =='k'])
    
    mani_feature_G = np.vstack(tuple([list_separated(layer)['manipulated'][1][idx] 
                                 for idx, pho in enumerate(list_separated(layer)['manipulated'][0]) if pho =='g']))
    mani_pho_G =np.array([], dtype='<U2')
    mani_pho_G = np.append(mani_pho_G, [pho for pho in list_separated(layer)['manipulated'][0] if pho =='g'])
    
    mani_feature_D = np.vstack(tuple([list_separated(layer)['manipulated'][1][idx] 
                                 for idx, pho in enumerate(list_separated(layer)['manipulated'][0]) if pho =='d']))
    mani_pho_D =np.array([], dtype='<U2')
    mani_pho_D = np.append(mani_pho_D, [pho for pho in list_separated(layer)['manipulated'][0] if pho =='d'])
    
    letter_dictio = {'p':{'original':(ori_pho_P, ori_feature_P), 'manipulated':(mani_pho_P, mani_feature_P)},
                    'b':{'original':(ori_pho_B, ori_feature_B), 'manipulated':(mani_pho_B, mani_feature_B)},
                    'd':{'original':(ori_pho_D, ori_feature_D), 'manipulated':(mani_pho_D, mani_feature_D)},
                    't':{'original':(ori_pho_T, ori_feature_T), 'manipulated':(mani_pho_T, mani_feature_T)},
                    'g':{'original':(ori_pho_G, ori_feature_G), 'manipulated':(mani_pho_G, mani_feature_G)},
                    'k':{'original':(ori_pho_K, ori_feature_K), 'manipulated':(mani_pho_K, mani_feature_K)}}
    
    
    return letter_dictio
    
    
    
